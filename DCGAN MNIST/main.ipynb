{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8DxDW97IZto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as tc\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rInEPWRJIglC",
        "colab_type": "code",
        "outputId": "8c857184-2045-430f-991e-e27ed8f9a26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = tc.device(\"cuda:0\" if (tc.cuda.is_available()) else \"cpu\")\n",
        "device"
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8wA3tmYImFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor()])\n",
        "mnist = torchvision.datasets.MNIST(root='./data/',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = tc.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfScoZ4iJyQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.deconv2 = nn.ConvTranspose2d(100, 512, 4, 1, 0)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(512)\n",
        "        self.deconv3 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(256)\n",
        "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(128)\n",
        "        self.deconv5 = nn.ConvTranspose2d(128, 1, 4, 2, 1)\n",
        "   \n",
        "    def forward(self, input):\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(input)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = F.tanh(self.deconv5(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE9HmqflJ75o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 128, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(128, 256, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3 = nn.Conv2d(256, 512, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(512)\n",
        "        self.conv5 = nn.Conv2d(512, 1, 4, 1, 0)\n",
        "    def forward(self, input):\n",
        "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.sigmoid(self.conv5(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGTahcprKT5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhr_m6jsKlBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss() \n",
        "def cost_G(output_G):\n",
        "    return tc.mean(-tc.log(D(output_G)))\n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002 \n",
        "optimizer_G = optim.Adam(G.parameters(), lr = lr)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr = lr)\n",
        "\n",
        "costs_G = []\n",
        "costs_D = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23eE9gyKtR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(50):\n",
        "  tic = time.time()\n",
        "  for i,data in enumerate(data_loader):\n",
        "    # Training the Discriminator\n",
        "    \n",
        "    D.zero_grad()\n",
        "    # Getting images from the training set\n",
        "    x,_ = data\n",
        "    # The images from the dataset are 28X28. We convert them to 32X32 images by padding.\n",
        "    # Also, the pixel intensities range from 0 to 1. We make them range from -1 to 1\n",
        "    x_real = tc.ones(batch_size,1,32,32).to(device)*(-1)\n",
        "    x_real[:,:,2:30,2:30] = x*2 - 1\n",
        "    # Calculating Discriminator output for images from the dataset. The label for images from the dataset is 1\n",
        "    output_D = D(x_real)\n",
        "    labels = tc.ones(batch_size).to(device)\n",
        "    # Calculating Discriminator loss for images from the dataset\n",
        "    real_loss = criterion(output_D[:,0,0,0],labels)\n",
        "    \n",
        "    # Images Generated by Generator\n",
        "    z = tc.randn(batch_sizee,z_dim,1,1).to(device)\n",
        "    x_fake = G(z)\n",
        "    # Calculating Discriminator output for images generated by the Genearator. The label for images generated by the Generator is 0\n",
        "    output_D = D(x_fake)\n",
        "    labels = tc.zeros(batch_size).to(device)\n",
        "    # Calculating Discriminator loss for images generated by the Genearator\n",
        "    fake_loss = criterion(output_D,labels)\n",
        "    \n",
        "    # Calculating the total Discrimantor loss\n",
        "    loss_D = real_loss + fake_loss\n",
        "    costs_D.append(loss_D)\n",
        "    print(i,'\\t',loss_D.item())\n",
        "    loss_D.backward()\n",
        "    optimizer_D.step()\n",
        "    \n",
        "    # Training the Generator\n",
        "   \n",
        "    G.zero_grad()\n",
        "    # Images Generated by Generator\n",
        "    z = tc.randn(batch_size, z_dim,1,1).to(device)\n",
        "    output_G = G(z)\n",
        "    # Calculating Generator loss\n",
        "    loss_G = cost_G(output_G)\n",
        "    costs_G.append(loss_G)\n",
        "    loss_G.backward()\n",
        "    optimizer_G.step()\n",
        "  toc = time.time()\n",
        "  print(toc - tic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZh5sjWiMmlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = tc.randn(batch_size,z_dim,1,1).to(device)\n",
        "plt.imshow(G(z)[0,0].detach().cpu(),cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Sq996rP5v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(costs_G,'b',label = 'Generator Loss')\n",
        "plt.plot(costs_D,'r',label = 'Discriminator Loss')\n",
        "plt.xlabel('Number of Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Generator and Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('plot1.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFCnY-61SMGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tc.save(G.state_dict(), 'G.pth')\n",
        "tc.save(D.state_dict(), 'D.pth')\n",
        "from google.colab import files\n",
        "files.download('G.pth') \n",
        "files.download('D.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}